# ğŸš€ Cybernetyka Teksty - Fine-tuning Bielik-11B

**Polski model AI wyspecjalizowany w cybernetyce** oparty na korpusie prac JÃ³zefa Kosseckiego i Mariana Mazura.

## ğŸ“š Co to jest?

Kompletny zestaw narzÄ™dzi do wytrenowania polskiego modelu jÄ™zykowego **Bielik-11B** na korpusie cybernetyki polskiej szkoÅ‚y:

- **ğŸ“– Korpus 11MB** - Wszystkie dostÄ™pne prace Kosseckiego + Mazura (OCR + rÄ™czne korekty)
- **ğŸ”¥ Fine-tuning** - Gotowe skrypty dla RTX 3090 (24GB VRAM)
- **ğŸ§ª Testy** - Automatyczne sprawdzanie jakoÅ›ci modelu
- **âš¡ Dwie metody** - Unsloth (szybka) i Standard (stabilna)

## ğŸ¯ Rezultat

Model ktÃ³ry rozumie i generuje teksty o:
- Cybernetyce spoÅ‚ecznej i kulturze
- Teorii ukÅ‚adÃ³w samodzielnych  
- Sterowaniu spoÅ‚ecznymi procesami
- Metacybernetyce i filozofii nauki
- Analizie systemÃ³w sterowania

## âš¡ Szybki Start

### 1. Klonuj repozytorium
```bash
git clone https://github.com/twÃ³j-user/cybernetyka_teksty.git
cd cybernetyka_teksty
```

### 2. Przygotuj Å›rodowisko
```bash
# Python 3.10+ + CUDA + RTX 3090
pyenv virtualenv 3.11.7 cybernetyka-finetune
pyenv activate cybernetyka-finetune
```

### 3. Uruchom automatyczny fine-tuning
```bash
./run_finetune.sh
```

Skrypt automatycznie:
- âœ… Sprawdzi Å›rodowisko  
- ğŸ§ª Przetestuje dostÄ™pnoÅ›Ä‡ bibliotek
- ğŸ¤– Pozwoli wybraÄ‡ metodÄ™ trenowania
- ğŸ”¥ Uruchomi fine-tuning (2-6h)
- ğŸ§ª Przetestuje wytrenowany model

## ğŸ“Š Metody Fine-tuningu

| Metoda | Czas | VRAM | StabilnoÅ›Ä‡ | KompatybilnoÅ›Ä‡ |
|--------|------|------|------------|----------------|
| **ğŸ¦¥ Unsloth** | 2-4h | 16-20GB | Niestabilna | Problematyczna |
| **ğŸ”§ Standard** | 3-6h | 22-24GB | Bardzo stabilna | Wysoka |

## ğŸ“ ZawartoÅ›Ä‡

```
cybernetyka_teksty/
â”œâ”€â”€ ğŸ“– cybernetyka_corpus.txt           # Korpus 11MB
â”œâ”€â”€ ğŸš€ run_finetune.sh                  # GÅ‚Ã³wny skrypt
â”œâ”€â”€ ğŸ¦¥ finetune_bielik.py               # Unsloth (szybkie)
â”œâ”€â”€ ğŸ”§ finetune_bielik_standard.py      # Standard (stabilne)
â”œâ”€â”€ ğŸ§ª test_finetuned_model.py          # Testy modelu
â”œâ”€â”€ ğŸ“¦ setup_environment.py             # Setup pakietÃ³w
â”œâ”€â”€ Kossecki/                           # Prace Kosseckiego
â”œâ”€â”€ Mazur/                              # Prace Mazura
â””â”€â”€ ğŸ“– README_FINETUNE.md               # SzczegÃ³Å‚owa dokumentacja
```

## ğŸ”§ Wymagania

### Hardware
- **RTX 3090** (24GB VRAM) lub lepsze
- **32GB+ RAM** 
- **50GB+ miejsca** na dysku

### Software  
- **Python 3.10+**
- **CUDA 12.1+**
- **PyTorch 2.4+**
- **Linux** (testowane na Manjaro/Ubuntu)

## ğŸ§ª PrzykÅ‚ad uÅ¼ycia

Po wytrenowaniu modelu:

```python
# ZaÅ‚aduj model
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel

base_model = AutoModelForCausalLM.from_pretrained("speakleash/Bielik-11B-v2.2-Instruct")
model = PeftModel.from_pretrained(base_model, "./bielik-cybernetyka-lora")
tokenizer = AutoTokenizer.from_pretrained("./bielik-cybernetyka-lora")

# Generuj tekst
prompt = "Co to jest cybernetyka spoÅ‚eczna wedÅ‚ug Kosseckiego?"
# ... model wygeneruje odpowiedÅº opartÄ… na korpusie
```

## ğŸ“– Dokumentacja

- **[ğŸ“‹ README_FINETUNE.md](README_FINETUNE.md)** - Kompletny przewodnik fine-tuningu
- **[ğŸ”„ TRANSFER_INSTRUCTIONS.md](TRANSFER_INSTRUCTIONS.md)** - Instrukcje przenoszenia miÄ™dzy systemami

## ğŸ¯ PrzykÅ‚ady odpowiedzi modelu

**Pytanie:** *"WyjaÅ›nij teoriÄ™ ukÅ‚adÃ³w samodzielnych Mazura"*

**Model:** *"Teoria ukÅ‚adÃ³w samodzielnych Mariana Mazura to fundamentalna koncepcja w cybernetyce polskiej szkoÅ‚y. UkÅ‚ad samodzielny to system zdolny do utrzymywania swojej struktury i funkcji w zmieniajÄ…cych siÄ™ warunkach Å›rodowiska poprzez mechanizmy sprzÄ™Å¼eÅ„ zwrotnych i autoregulacji..."*

## ğŸ“Š Statystyki korpusu

- **ğŸ“š Dokumenty:** ~150 prac naukowych
- **ğŸ“„ Tekst:** 11MB czystego tekstu polskiego  
- **ğŸ·ï¸ Tematyka:** Cybernetyka, socjotechnika, metacybernetyka
- **ğŸ‘¨â€ğŸ”¬ Autorzy:** JÃ³zef Kossecki, Marian Mazur
- **ğŸ“… Okres:** 1960-2010
- **âœ… JakoÅ›Ä‡:** OCR + rÄ™czne korekty

## ğŸš€ Status projektu

- âœ… **Korpus gotowy** - 11MB wysoce jakoÅ›ciowych tekstÃ³w
- âœ… **Fine-tuning dziaÅ‚a** - Przetestowane na RTX 3090
- âœ… **Dwie metody** - Unsloth i Standard
- âœ… **Automatyzacja** - Jeden skrypt uruchamia wszystko
- ğŸ”„ **Testowanie** - CiÄ…gÅ‚e ulepszanie jakoÅ›ci

## ğŸ¤ WkÅ‚ad

Mile widziane:
- ğŸ› **ZgÅ‚oszenia bÅ‚Ä™dÃ³w**
- ğŸ’¡ **Sugestie ulepszeÅ„**  
- ğŸ“ **Korekty korpusu**
- ğŸ”§ **Optymalizacje kodu**

## ğŸ“„ Licencja

- **Kod:** MIT License
- **Korpus:** Dozwolony uÅ¼ytek naukowy/edukacyjny
- **Model:** WedÅ‚ug licencji Bielik-11B

## ğŸ† Cel projektu

Stworzenie **pierwszego polskiego modelu AI wyspecjalizowanego w cybernetyce**, ktÃ³ry:
- ğŸ§  Rozumie terminologiÄ™ polskiej szkoÅ‚y cybernetycznej
- ğŸ“š Opiera odpowiedzi na pracach Kosseckiego i Mazura  
- ğŸ”¬ MoÅ¼e wspieraÄ‡ badania i edukacjÄ™ w cybernetyce
- ğŸ‡µğŸ‡± Zachowuje polski kontekst naukowy

---

**ğŸ’¡ Zbuduj swojego eksperta AI w cybernetyce w 6 godzin!**

**â­ JeÅ›li projekt Ci siÄ™ podoba - zostaw gwiazdkÄ™!** 